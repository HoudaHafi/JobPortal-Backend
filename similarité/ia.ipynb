{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\houda\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import docx  # python-docx for DOCX\n",
    "from PIL import Image  # for image handling\n",
    "import pytesseract  # Tesseract OCR for text extraction from images\n",
    "from io import BytesIO\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from flask import Flask, request, jsonify\n",
    "import base64\n",
    "from flask_cors import CORS\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle de embeddings multilingue\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job (['Git', 'Kubernetes', 'Docker', 'MySQL', 'Java'], 2)\n",
      "cvs [(38, '20240909_174941_CV Feriel Ben Kraiem.pdf'), (39, '20240909_175146_CV_MOHAMED ALI MNASSAR.pdf'), (40, '20240909_175301_CV_Fkiri GHAZI.pdf'), (41, '20240909_175337_CV_Rim_Elhafi.pdf'), (42, '20240909_175419_CV_houda.pdf'), (37, '20240909_174830_CV_Wissem TRABELSSI.pdf')]\n",
      "cv_degrees ['Ingénieur']\n",
      "cv_skills ['Avancé', 'C++', 'Boot', 'Postgresql', 'Des', 'Jenkins', 'Zabbix', 'Python', 'Internet', 'Git', 'Hibernate', 'Jira', 'Mariadb', 'Ci', 'Apache', 'Firebase', 'Nginx', 'Application', 'Spring', 'Cd', 'Bitbucket', 'Github', 'Ssh', 'Intermédiaire', 'Dart', 'Ldap', 'Mobile', 'Mysql', 'Reconnaissance', 'Devops', 'Vagrant', 'Surveillance', 'Docker', 'Au', 'Web', 'Parole', 'Typescript', 'Stm', 'Java', 'C', 'Ansible', 'Reactjs', 'Angular']\n",
      "cv_degrees ['Ingénieur']\n",
      "cv_skills ['Openshift', 'Avancé', 'Virtualisation', 'Eureka', 'Computing', 'Des', 'F', 'O', 'Python', 'Maps', 'Box', 'Git', 'Passport', 'Hibernate', 'Json', 'Fog', 'Kubernetes', 'Application', 'R', 'Edge', 'Prompt', 'Models', 'Collaboration', 'Php', 'Spring', 'Html', 'Microsoft', 'Github', 'Research', 'Css', 'Javascript', 'Ibm', 'Sms', 'Api', 'Keywords', 'Flask', 'Mobile', 'Azure', 'Fundamentals', 'Video', 'Nlp', 'Fuzzing', 'Devops', '.net', 'Proxy', 'N', 'Docker', 'Gateway', 'Microservices', 'Au', 'Web', 'Cloud', 'Google maps api', 'Google', 'Learning', 'Ieee', 'C', 'Java', 'Laravel', 'Orchestration', 'Blockchain', 'D', 'X', 'Angular', 'Camp']\n",
      "cv_degrees ['Ingénieur']\n",
      "cv_skills ['C++', 'Des', 'Python', 'Numpy', 'Git', 'Pandas', 'Base', 'Cancer', 'Mongodb', 'Html', 'Commerce', 'Languages', 'Github', 'Oracle', 'Jquery', 'Css', 'Javascript', 'Dart', 'Springboot', 'Flask', 'Framework', 'Si', 'Nlp', 'Mysql', 'Devops', 'Docker', 'Web', 'Typescript', 'Ionic', 'Learning', 'C', 'Java', 'Keras', 'Coursera', 'Angular']\n",
      "cv_degrees []\n",
      "cv_skills ['Programmes', 'Des', 'F', 'O', 'Coaching', 'Observation', 'R', 'Conduit', 'Gym', 'Plateau', 'N', 'Participation', 'Posture', 'Cardio', 'C', 'Fitness', 'Adapter', 'Sports', 'D']\n",
      "cv_degrees ['Ingénieur']\n",
      "cv_skills ['Mes', 'C++', 'Boot', 'Postgresql', 'Des', 'Express.js', 'Technologie', 'Python', 'Parsing', 'Bootstrap', 'Forte', 'Application', 'Mongodb', 'Tri', 'Html', 'Spring', 'Languages', 'Css', 'Javascript', 'Flask', 'Mobile', 'Si', 'Reconnaissance', 'Database', 'Web', 'Typescript', 'Architecture', 'Java', 'C', 'Connect', 'Blockchain', 'Reactjs', 'Angular']\n",
      "cv_degrees ['Ingénieur']\n",
      "cv_skills ['Linux', 'C++', 'Bootstrap', 'Android', 'Xml', 'Des', 'Boot', 'Python', 'Git', 'Kubernetes', 'Apache', 'Nginx', 'Base', 'Messagerie', 'R', 'Matching', 'Html', 'Php', 'Spring', 'Logstash', 'Yaml', 'Github', 'Microsoft', 'Oracle', 'Css', 'Javascript', 'Plus', 'Sql', 'Otrs', 'Studio', 'Azure', 'Mysql', 'Cards', 'Devops', 'Database', 'Docker', 'Web', 'Cloud', 'Windows', 'Gitlab', 'Elasticsearch', 'Android studio', 'Java', 'C', 'Ansible', 'Postfix', 'Google']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Sep/2024 20:32:03] \"GET /similarity/10 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ID: 37, Distance: 0.8053015470504761\n",
      "CV ID: 38, Distance: 0.8195537328720093\n",
      "CV ID: 40, Distance: 0.8750857710838318\n",
      "CV ID: 42, Distance: 1.0594874620437622\n",
      "CV ID: 39, Distance: 1.0600297451019287\n",
      "CV ID: 41, Distance: 1.7523140907287598\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, resources={r\"/similarity/*\": {\"origins\": \"http://localhost:4200\"}})\n",
    "\n",
    "nlp_fr = spacy.load('fr_core_news_sm')\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Liste des diplômes\n",
    "DEGREES = [\"licence\", \"master\",\"ingénieur\"]\n",
    "\n",
    "# Fonction pour extraire les diplômes d'un texte de CV\n",
    "def extract_degree(resume_text):\n",
    "    nlp_text = nlp_fr(resume_text)\n",
    "    degrees = []\n",
    "    for token in nlp_text:\n",
    "        if token.text.lower() in DEGREES:\n",
    "            degrees.append(token.text)\n",
    "    for chunk in nlp_text.noun_chunks:\n",
    "        chunk_text = chunk.text.lower().strip()\n",
    "        if chunk_text in DEGREES:\n",
    "            degrees.append(chunk.text)\n",
    "    return [word.capitalize() for word in set(degrees)]\n",
    "\n",
    "# Charger la base de données des compétences à partir d'un fichier externe\n",
    "with open('linkedin') as f:\n",
    "    external_source = list(f)\n",
    "\n",
    "result = [element.strip().lower() for element in external_source]\n",
    "\n",
    "# Fonction pour extraire les compétences d'un texte de CV\n",
    "def extract_skill(resume_text):\n",
    "    nlp_text = nlp_en(resume_text)\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    skills = result\n",
    "    skillset = []\n",
    "    for i in tokens:\n",
    "        if i.lower() in skills:\n",
    "            skillset.append(i)\n",
    "    for i in nlp_text.noun_chunks:\n",
    "        i = i.text.lower().strip()\n",
    "        if i in skills:\n",
    "            skillset.append(i)\n",
    "    return [word.capitalize() for word in set([word.lower() for word in skillset])]\n",
    "\n",
    "# Connexion à la base de données PostgreSQL\n",
    "def connect_db():\n",
    "    return psycopg2.connect(\n",
    "        host='localhost',\n",
    "        user='postgres',\n",
    "        password='root',\n",
    "        database='projet'\n",
    "    )\n",
    "\n",
    "def extract_text(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith('.jpg') or file_path.endswith('.png') or file_path.endswith('.tiff') or file_path.endswith('.gif'):\n",
    "        return extract_text_from_image(file_path)\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# Fonction pour extraire le texte d'un document à partir d'un chemin de fichier    \n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(\"c:/file/\"\n",
    "+docx_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "# Fonction pour extraire le texte d'une image à partir d'un chemin de fichier\n",
    "def extract_text_from_image(image_path):\n",
    "    img = Image.open(\"c:/file/\"\n",
    "+image_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "# Fonction pour extraire le texte d'un PDF à partir d'un chemin de fichier\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_data = fitz.open(\"c:/file/\"\n",
    "+pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(pdf_data)):\n",
    "        page = pdf_data.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Fonction pour récupérer les informations sur un job par son ID\n",
    "def get_job_by_id(cursor, job_id):\n",
    "    cursor.execute(\"SELECT requirements, niveau FROM job WHERE id = %s\", (job_id,))\n",
    "    job = cursor.fetchone()\n",
    "    return job\n",
    "\n",
    "# Fonction pour récupérer les CVs pour une offre d'emploi spécifique\n",
    "def get_cvs_by_job_id(cursor, job_id):\n",
    "    cursor.execute(\"SELECT id, cv FROM job_application WHERE job_id = %s\", (job_id,))\n",
    "    cvs = cursor.fetchall()\n",
    "    return cvs\n",
    "\n",
    "# Fonction pour récupérer les détails des postulations par leurs IDs dans le bon ordre\n",
    "def get_postulations_by_ids(cursor, postulation_ids):\n",
    "    if not postulation_ids:\n",
    "        return []\n",
    "\n",
    "    format_strings = ','.join(['%s'] * len(postulation_ids))\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT \n",
    "            ja.id, ja.cv, ja.datecandidateur, ja.status, ja.title,\n",
    "            c.first_name, c.last_name, c.niveau, c.email, c.telephone,ja.condidate_id,ja.job_id\n",
    "        FROM job_application ja\n",
    "        JOIN candidat c ON ja.condidate_id = c.id\n",
    "        WHERE ja.id IN ({format_strings})\n",
    "        ORDER BY array_position(ARRAY[{format_strings}], ja.id)\n",
    "    \"\"\", tuple(postulation_ids) + tuple(postulation_ids))\n",
    "    postulations = cursor.fetchall()\n",
    "    return postulations\n",
    "\n",
    "@app.route('/similarity/<int:job_id>', methods=['GET'])\n",
    "def calculate_similarity(job_id):\n",
    "    db_conn = connect_db()\n",
    "    cursor = db_conn.cursor()\n",
    "    \n",
    "    job = get_job_by_id(cursor, job_id)\n",
    "    print(\"job\",job)\n",
    "    \n",
    "    if not job:\n",
    "        cursor.close()\n",
    "        db_conn.close()\n",
    "        return jsonify({'message': 'Job not found'}), 404\n",
    "    \n",
    "    # Générer les embeddings pour la description du job\n",
    "    job_text = \" \".join([str(item) for sublist in job for item in (sublist if isinstance(sublist, list) else [sublist])])\n",
    "    job_embedding = model.encode([job_text])\n",
    "    # Récupérer les CVs pour cette offre d'emploi\n",
    "    cvs = get_cvs_by_job_id(cursor, job_id)\n",
    "    print(\"cvs\",cvs)\n",
    "    \n",
    "    if not cvs:\n",
    "        cursor.close()\n",
    "        db_conn.close()\n",
    "        return jsonify({'message': 'No CVs found for this job'}), 404\n",
    "    \n",
    "    cv_texts = []\n",
    "    for cv in cvs:\n",
    "        cv_id, cv_blob = cv\n",
    "        cv_text = extract_text(cv_blob)\n",
    "     \n",
    "        cv_degrees = extract_degree(cv_text)\n",
    "        print(\"cv_degrees\", cv_degrees)\n",
    "    \n",
    "        cv_skills = extract_skill(cv_text)\n",
    "        print(\"cv_skills\", cv_skills)\n",
    "        cv_combined_text = \" \".join(cv_degrees + cv_skills)\n",
    "        cv_texts.append((cv_id, cv_combined_text))\n",
    "    \n",
    "    # Générer les embeddings pour les CVs\n",
    "    cv_embeddings = model.encode([cv_text for _, cv_text in cv_texts])\n",
    "    \n",
    "    # Convertir les embeddings en matrices NumPy\n",
    "    job_embedding = np.array(job_embedding)\n",
    "    cv_embeddings = np.array(cv_embeddings)\n",
    "    \n",
    "    # Utiliser FAISS pour créer une instance de recherche de vecteurs pour les CVs\n",
    "    index = faiss.IndexFlatL2(cv_embeddings.shape[1])\n",
    "    index.add(cv_embeddings)\n",
    "    \n",
    "    # Calculer la similarité des CVs avec le job\n",
    "    D, I = index.search(job_embedding, len(cv_embeddings))  # Trouver la similarité avec l'offre d'emploi\n",
    "    \n",
    "    # Afficher les IDs des CVs et leurs distances dans la console\n",
    "    for idx, distance in zip(I[0], D[0]):\n",
    "        print(f\"CV ID: {cvs[idx][0]}, Distance: {distance}\")\n",
    "    \n",
    "    # Trier les résultats par similarité\n",
    "    results = sorted(zip(I[0], D[0]), key=lambda x: x[1])\n",
    "    \n",
    "    sorted_cv_ids = [cvs[idx][0] for idx, _ in results]\n",
    "  \n",
    "    # Récupérer les détails des postulations triées par similarité\n",
    "    sorted_postulations = get_postulations_by_ids(cursor, sorted_cv_ids)\n",
    "    \n",
    "    # Convertir les résultats en un format sérialisable en JSON\n",
    "    serialized_postulations = []\n",
    "    for p in sorted_postulations:\n",
    "        serialized_postulations.append({\n",
    "           'id': p[0], 'cv': p[1], 'datecandidateur': p[2], 'status': p[3],\n",
    "            'title': p[4], 'firstName': p[5], 'lastName': p[6], 'niveau': p[7],\n",
    "            'email': p[8], 'telephone': p[9], 'candidat': p[10], 'job': p[11]\n",
    "        })\n",
    "    \n",
    "    cursor.close()\n",
    "    db_conn.close()\n",
    "    return jsonify(serialized_postulations), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
